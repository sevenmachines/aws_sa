\head{Expansion}

\subhead{Overview}
	
Building on the initial solution but with the use of a number of additional AWS services, we can make the site scale globally and meet the performance demands of a high capacity business.

\architecture
{aws_sa_v2_simple}
{Large scalable production solution}

\changes
{Global scale improvements}
{
\item \label{item:aws_sa_v2_simple_cloudfront} Cloudfront provides cached content from edge locations around the world \cite{cfn-api}. 
\item \label{item:aws_sa_v2_simple_s3_origin} A secured S3 bucket provides a highly scalable source of static content
\item \label{item:aws_sa_v2_simple_alb} Active content is sourced through a public application load balancer (ALB).
\item \label{item:aws_sa_v2_simple_waf} WAF is configured with rules in front of the ALB \cite{ AWS-shield, waf-apiref, waf-dg}
\item \label{item:aws_sa_v2_simple_azs} Applications requiring public internet addresses are installed on EC2 instances controlled by an auto-scaling group (ASG) in public subnets distributed across more than one availability zone.
\item \label{item:aws_sa_v2_simple_nat} The NAT gateway service provides address translation to allow outbound internet access for the private subnets.
\item \label{item:aws_sa_v2_simple_private} Applications that do not require public internet addresses are installed on EC2 instances inside an ASG in private subnets distributed across more than one availability zone.
\item \label{item:aws_sa_v2_simple_elasticache} Elasticache (redis) provides in-memory caching for the database backend. Using multi-node with clustering helps performance, reliability, and scalability \cite{redis-ug}. 

\item \label{item:aws_sa_v2_simple_rds} RDS in multi-AZ mode gives resilient failover from primary to secondary, as well as < 5 min point in time recovery \cite{rds-api}.
\item \label{item:aws_sa_v2_simple_secrets} Secrets manager works with the Key Management Service (KMS) to allow instances with the right IAM roles to access their relevant credentials \cite{secretsmanager-userguide}.
}

\subhead{Pillars}

\subsubhead{Operational}

The addition of Cloudfront and WAF metrics means that observability of the customers usage and experiences with the site overall are covered in more depth. Additional origins can be added in, meaning that new infrastructure can be added into the main site easily.

\subsubhead{Security}

By moving as much of the application into non-accessible private subnets, the exposure of running services to attack is greatly reduced. In addition, strong security group and NACL rules can protect the independent application and data components. There may be options depending on the behaviour of the services moving forward to restrict access to running services further and integrate private subnets with VPC endpoint services to prevent internal traffic traversing networks outside of AWS.

Cloudfront can also be set to filter requests, allow only certain request types, filter cookies, etc. Meaning there the site can be restricted to the smallest set of requests that it needs to be functional for the end-users.

Although bastion servers are an option, access to private servers could be added through the SSM session manager and IAM user access. This not only removes the need to run publicly exposed bastion servers, but also means that access can be logged and audited through Cloudtrail.

Secrets access is kept secure through AWS Secrets manager, allowing services to have granular access to encrypted data during runtime. There is also the option of regularly rotating credentials such as database passwords.

\subsubhead{Reliability}

The caching provided by Cloudfront means that the site can remain functional if degraded, for users even in the event of the servers becoming unavailable. Finely controlled fallback to a static version of the site or other sources through the use of origin groups.

The use of Elasticache Redis in multi-node with clustering enabled means that data is sharded and those shards replicated across AZs, adding resilience.

\subsubhead{Performance}

The use of Cloudfront for static assets such as images, videos, and Javascript, means that the performance and network transfer overhead is moved from the EC2 instances onto globally distributed edge locations. This gives greater responsiveness for users and higher availability assurances. With the Elasticache clustering, we can have multiple sources of each data shard cached from the database, improving throughput.


\subsubhead{Cost} 

Moving assets to edge locations reduces bandwidth costs for moving data through the network, as well as reducing the needed EC2 compute power to run the service. Although we add cost through having Elasticache in multi-nodes setup, we constrain this by clustering so that we can horizontally scale our cache, rather than buying more expensive instance types. The cost-performance trade-off will need to be balanced dependent on the customer need and requirements.

\subhead{Summary}

This possible configuration builds upon the initial basic implementation and incorporates features that support a globally scalable customer service. The infrastructure costs are kept minimal, with costs scaling efficiently with traffic increase. The use of CDN, database caching, and auto-scaling mean that customer response times and availbility are maintained even with high rates of customer engagement, even given a variety of traffic across multimedia, static, and dynamic requests.
